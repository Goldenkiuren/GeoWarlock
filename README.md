# ğŸ§™â€â™‚ï¸ GeoWarlock: GeolocalizaÃ§Ã£o Visual com Vision Transformers e DinoV2

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-ee4c2c)
![DinoV2](https://img.shields.io/badge/Meta-DinoV2-green)
![Status](https://img.shields.io/badge/Status-ConcluÃ­do-success)

> **GeoWarlock** Ã© um sistema de Deep Learning desenvolvido para tarefas de geolocalizaÃ§Ã£o baseada em imagens (Image-to-GPS/City). O projeto realiza uma anÃ¡lise comparativa entre arquiteturas Vision Transformer clÃ¡ssicas (ViT-16) e modelos auto-supervisionados modernos (DinoV2) utilizando o dataset Mapillary Street-Level Sequences.

---

## ğŸ‘¥ Autores
* **Augusto Mattei Grohmann**
* **Angelo Fernandes Oliveira**

---

## ğŸ¯ Objetivo e Metodologia
O objetivo deste projeto Ã© classificar a cidade de origem de uma imagem de rua, mitigando problemas clÃ¡ssicos de *data leakage* em sÃ©ries temporais de imagens.

### ğŸ§  Arquiteturas Comparadas
O projeto implementa e compara trÃªs abordagens distintas:
1.  **ViT-B/16 (Supervisionado):** Modelo prÃ©-treinado na ImageNet-1k, servindo como baseline.
2.  **DinoV2 Frozen (Self-Supervised):** Utiliza o backbone do DinoV2 (ViT-B/14) com pesos congelados como extrator de caracterÃ­sticas, treinando apenas o classificador (Head).
3.  **DinoV2 Fine-Tuned:** Ajuste fino completo do backbone DinoV2 e do classificador, com taxas de aprendizado diferenciais para preservar o conhecimento prÃ©vio.

### ğŸ›¡ï¸ EstratÃ©gia de Treinamento
* **Split Espacial (K-Means):** Para evitar vazamento de dados (onde imagens da mesma rua aparecem no treino e validaÃ§Ã£o), implementou-se uma divisÃ£o baseada em clusters de coordenadas GPS usando K-Means.
* **Balanceamento de Classes:** UtilizaÃ§Ã£o de `WeightedRandomSampler` para lidar com a disparidade no nÃºmero de imagens entre cidades.
* **Data Augmentation:** AplicaÃ§Ã£o de `RandomResizedCrop`, `ColorJitter`, rotaÃ§Ãµes e flips para forÃ§ar o modelo a aprender caracterÃ­sticas estruturais e nÃ£o apenas memorizar pixels.

---

## ğŸ“Š Resultados
O estudo, realizado com 28 classes (cidades), demonstrou a superioridade das abordagens auto-supervisionadas:

| Modelo | AcurÃ¡cia ValidaÃ§Ã£o | ObservaÃ§Ãµes |
| :--- | :--- | :--- |
| **ViT-16** | ~83.5% | Apresentou sinais de overfitting apÃ³s a 4Âª Ã©poca. |
| **DinoV2 Frozen** | ~92.6% | Melhor generalizaÃ§Ã£o em testes externos (Street View), com 100% de acerto na Europa. |
| **DinoV2 Tuned** | **>94%** | Maior acurÃ¡cia bruta, porÃ©m com maior custo computacional. |

---

## ğŸ“‚ Estrutura do Projeto

### Scripts de Treinamento
* `main_vit.py`: Pipeline de treinamento para o Vision Transformer clÃ¡ssico.
* `main_frozen_dino.py`: Treinamento do classificador linear sobre o backbone congelado do DinoV2.
* `main_dino.py`: Fine-tuning completo do DinoV2 com LR diferencial (Backbone: 5e-6, Head: 1e-4).

### Scripts de InferÃªncia e Teste
* `geowarlock_city_guesser.py`: AplicaÃ§Ã£o GUI (Interface GrÃ¡fica) desenvolvida em CustomTkinter. Permite carregar uma imagem e obter prediÃ§Ãµes em tempo real usando qualquer um dos trÃªs modelos[cite: 147, 148].
* `batch_test_*.py`: Scripts para avaliaÃ§Ã£o em lote em pastas de teste, utilizando **Test-Time Augmentation (FiveCrop)** para aumentar a robustez da prediÃ§Ã£o[cite: 108, 110].

---

## ğŸš€ InstalaÃ§Ã£o e Uso

### PrÃ©-requisitos

* Python 3.10+
* GPU com suporte a CUDA (recomendado para treino; CPU funciona para inferÃªncia mas Ã© muito lento)
* Git (opcional, para clonar o repositÃ³rio)

> **RecomendaÃ§Ã£o:** crie um ambiente virtual antes de instalar dependÃªncias:

```bash
# Unix / macOS
python -m venv .venv
source .venv/bin/activate

# Windows (PowerShell)
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### InstalaÃ§Ã£o das dependÃªncias

```bash
# Instalar requisitos
pip install -r requirements.txt

# Ou instalar o pacote local (opcional)
pip install -e .
```

Se quiser reproduzir exatamente o ambiente, inclua um `requirements-lock.txt` ou um `environment.yml` (conda).

---

## ğŸ”§ Executando a Interface GrÃ¡fica (GeoWarlock)

A GUI permite carregar uma imagem e obter a prediÃ§Ã£o de cidade em tempo real.

```bash
# Exemplo: abrir a GUI usando um modelo especÃ­fico
python geowarlock_city_guesser.py --model best_models/dino_finetuned.pth
```

**ObservaÃ§Ãµes:**
* Coloque os checkpoints `.pth` na pasta `best_models/` ou aponte com `--model` para o caminho correto.
* A GUI usa CustomTkinter; se houver problemas com o back-end, verifique a versÃ£o do `tkinter` e a compatibilidade da sua plataforma.

---

## ğŸ‹ï¸ Executando o Treinamento

Exemplo de comando para o fine-tuning do DinoV2 com taxas de aprendizado diferenciadas:

```bash
python main_dino.py \
  --data-dir data/ \
  --epochs 30 \
  --batch-size 64 \
  --lr-backbone 5e-6 \
  --lr-head 1e-4 \
  --output-dir runs/dino_finetuned \
  --seed 42
```

Para treinar apenas o classificador sobre o backbone congelado:

```bash
python main_frozen_dino.py --data-dir data/ --epochs 20 --batch-size 128 --output-dir runs/dino_frozen
```

E para o ViT baseline:

```bash
python main_vit.py --data-dir data/ --epochs 30 --batch-size 64 --output-dir runs/vit_baseline
```

> **Dica:** inclua `--resume` ou `--checkpoint` nos scripts para facilitar retomar treinamentos interrompidos.

---

## ğŸ§ª Teste em Lote e Test-Time Augmentation

Exemplo de uso do script de avaliaÃ§Ã£o em lote com TTA (FiveCrop):

```bash
python batch_test.py --model best_models/dino_frozen.pth --input-dir test_images/ --tta fivecrop --output results/batch_results.csv
```

---

## ğŸ“ Estrutura esperada do dataset

O repositÃ³rio assume a seguinte organizaÃ§Ã£o mÃ­nima do dataset (`data/`):

```
data/
â”œâ”€ Amsterdam/
â”‚  â”œâ”€ img_000001.jpg
â”‚  â””â”€ img_000002.jpg
â”œâ”€ BuenosAires/
â”‚  â””â”€ ...
â””â”€ SÃ£oPaulo/
   â””â”€ ...
```

* Cada pasta representa uma classe (cidade).
* No processamento que utilizamos, filtramos cidades com menos de 200 imagens e usamos splitting espacial (K-Means sobre coordenadas) para evitar data leakage entre treino/val.
* Se houver metadados (CSV com `filename,lat,lon,sequence_id`), descreva o formato esperado e onde colocÃ¡-lo (ex.: `data/metadata.csv`).

---

### ğŸŒ Dataset

O projeto utiliza uma versÃ£o curada do Mapillary Street-Level Sequences (MSLS). As classes incluem cidades como: Amsterdam, Buenos Aires, Tokyo, SÃ£o Paulo, Paris, entre outras (totalizando 28 cidades apÃ³s filtragem de classes com menos de 200 imagens).